{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from scipy.spatial import distance\n",
    "from n2i.__main__ import n2i_main, n2i_nx_graph\n",
    "from n2i.node2vec import read_graph\n",
    "\n",
    "%pylab inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_path = '../data/graph/lesmiserables/lesmiserables_edgelist.txt'\n",
    "\n",
    "graph = read_graph(weighted=False, \n",
    "               graph=graph_path,\n",
    "               directed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "emb = n2i_nx_graph(nx_graph=graph, topics=3, tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between connected nodes\n",
    "def sim_in(G):\n",
    "    sims = []\n",
    "    for i in G.nodes:\n",
    "        for j in list(G.neighbors(i)):\n",
    "            sims.append(1 - distance.cosine(G.nodes[i]['interests'], G.nodes[j]['interests']))\n",
    "    return np.mean(sims)\n",
    "\n",
    "def select_notedge(G):\n",
    "    v1 = np.random.choice(G.nodes())\n",
    "    v2 = np.random.choice(G.nodes())\n",
    "\n",
    "    while (v1,v2) in G.edges or v1==v2:\n",
    "        v1 = np.random.choice(G.nodes())\n",
    "        v2 = np.random.choice(G.nodes())\n",
    "    return v1, v2\n",
    "#     n = nx.number_of_nodes(G)\n",
    "#     while True:\n",
    "#         a, b = np.random.randint(0, n, size=2)\n",
    "#         if (a, b) not in G.edges:\n",
    "#             return a, b\n",
    "\n",
    "# similarity between disconnected nodes\n",
    "def sim_out(G, samples):\n",
    "    sims_out = []\n",
    "    for c in range(samples):\n",
    "        i, j = select_notedge(G)\n",
    "        sims_out.append(1 - distance.cosine(G.nodes[i]['interests'], G.nodes[j]['interests']))\n",
    "    return np.mean(sims_out)\n",
    "\n",
    "def homophily(G):\n",
    "    return sim_in(G) / sim_out(G, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = '../data/graph/lesmiserables/lesmiserables_edgelist.txt'\n",
    "G = read_graph(weighted=False, \n",
    "               graph=graph,\n",
    "               directed=False)\n",
    "p_val = [0.1, 0.25, 0.5, 0.75, 1.25, 1.5, 1.75, 2, 4, 8, 10, 20, 40]\n",
    "q_val = [0.1, 0.25, 0.5, 0.75, 1.25, 1.5, 1.75, 2, 4, 8, 10, 20, 40]\n",
    "\n",
    "topics=[15]\n",
    "dimensions=[128]\n",
    "walk_length=[80]\n",
    "num_walks=[10]\n",
    "window_size=[10]\n",
    "iiter=[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = []\n",
    "\n",
    "nr_experiments = 20\n",
    "\n",
    "for t in topics:\n",
    "    for d in dimensions:\n",
    "        for wk in walk_length:\n",
    "            for n in num_walks:\n",
    "                for wi in window_size:\n",
    "                    for ii in iiter:\n",
    "                        for p in p_val:\n",
    "                            for q in q_val:\n",
    "                                for seed in range(nr_experiments):\n",
    "                                    args = [t, d, wk, n, wi, ii, p, q, seed]\n",
    "                                    args_list.append(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(*args):\n",
    "    t, d, wk, n, wi, ii, p, q, seed = args\n",
    "    G_emb = n2i_nx_graph(nx_graph=G, topics=t, \n",
    "             dimensions=d, walk_length=wk,\n",
    "             num_walks=n, window_size=wi,\n",
    "             iiter=ii, p=p, q=q,\n",
    "             seed = seed + int(1000*(q+p)))\n",
    "    for i in G.nodes:\n",
    "        G.node[i]['interests'] = G_emb[i]\n",
    "    si = sim_in(G)\n",
    "    so = sim_out(G, 5000)\n",
    "    return args + (si/so,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = list(map(lambda x: run_experiment(*x), args_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result, columns=['t', 'd', 'wk', 'n', 'wi', 'ii', 'p', 'q', 'seed', 'hom'])\n",
    "df2 = df.groupby(['p', 'q'])['hom'].mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc()[[2420]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(df2)\n",
    "plt.title('Homophily (mean of 20 realizations)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(graph, weighted, directed):\n",
    "    '''\n",
    "    Pipeline for the heatmap creation\n",
    "    '''\n",
    "    # read graph\n",
    "    G = graph\n",
    "    # experiments\n",
    "    result = list(map(lambda x: run_experiment(*x), args_list))\n",
    "    # df\n",
    "    df = pd.DataFrame(result, columns=['t', 'd', 'wk', 'n', 'wi', 'ii', 'p', 'q', 'seed', 'hom'])\n",
    "    df2 = df.groupby(['p', 'q'])['hom'].mean().unstack()\n",
    "    \n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.karate_club_graph()\n",
    "weighted =  False if graph.edge_attr_dict_factory() == {} else True\n",
    "directed = graph.is_directed()\n",
    "df = analysis(graph, weighted, directed)\n",
    "\n",
    "# plot\n",
    "sns.heatmap(df)\n",
    "plt.title('Homophily (mean of 20 realizations)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = n2i_nx_graph(nx_graph=graph, topics=12, tf=True, seed=10, translate=False, reduce=False, \n",
    "                   window_size=20,\n",
    "                   walk_length=100,\n",
    "                   num_walks=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "for u, v in graph.edges():\n",
    "    arr_u = list(emb[u])\n",
    "    arr_v = list(emb[v])\n",
    "    X.append(arr_u + arr_v)\n",
    "    y.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as IT\n",
    "import random\n",
    "\n",
    "missing = [pair for pair in IT.combinations(graph.nodes(), 2) if not graph.has_edge(*pair)]\n",
    "no_edges = random.choices(missing, k=len(graph.edges()))\n",
    "for u, v in no_edges:\n",
    "    arr_u = list(emb[u])\n",
    "    arr_v = list(emb[v])\n",
    "    X.append(arr_u + arr_v)\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-vs-rest logistic regression object\n",
    "clf = LogisticRegression(random_state=0, multi_class='ovr')\n",
    "# Train model\n",
    "model = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7738095238095238"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_score(**kwargs):\n",
    "    for key, value in kwargs.items():\n",
    "        print(key, value)\n",
    "        prova(value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_score(topics=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prova(i):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
