{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *WoMG*: tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial for *WoMG*. The WoMG software generates synthetic datasets of documents cascades on network. It starts with any (un)directed, (un)weighted graph and a collection of documents and it outputs the propagation DAGs of the docs through the network. Diffusion process is guided by the nodes underlying preferences.\n",
    "\n",
    "\n",
    "First section will introduce a demo of the software.\n",
    "\n",
    "Second section will provide a basic usage with the [Digg](https://www.isi.edu/~lerman/downloads/digg2009.html) dataset used in the thesis. Digg dataset contains a network dataset and a propagation dataset.\n",
    "\n",
    "The Analysis section will analyse the synthetic dataset of propagations generated by WoMG using the Digg network as input graph; the real propagation values are reported at the end of the previous section. \n",
    "\n",
    "The statistics section is used for simulating different propagations with different parameters and plotting the results; this kind of statistics needs lot of computation by WoMG, so synthetic datasets are already produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOC:\n",
    "* [Demo](#Demo)\n",
    "* [Help](#Help)\n",
    "* [Usage](#Usage)\n",
    "* [Analysis](#Analysis)\n",
    "* [ESPERIMENTS](#ESPERIMENTS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WoMG can be used both in command line and Jupyter notebook. The following codes will run WoMG with the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%run ../src/womg/__main__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:00<00:00, 481189.35it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 242281.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No graph path provided \n",
      " DEMO Mode: generating cascades in les miserables network\n",
      "Formatting graph:\n",
      "Setting god node\n",
      "Generating interests with nmf ..\n",
      "Setting LDA in generative mode:  30  documents, with  15  topics.\n",
      "Training the LDA model ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/Users/Cinus/Library/Python/3.6/lib/python/site-packages/numpy/matrixlib/defmatrix.py:71: PendingDeprecationWarning: the matrix subclass is not the recommended way to represent matrices or deal with linear algebra (see https://docs.scipy.org/doc/numpy/user/numpy-for-matlab-users.html). Please adjust your code to use regular ndarray.\n",
      "  return matrix(data, dtype=dtype, copy=False)\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 30/30 [00:00<00:00, 4141.30it/s]\u001b[A\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 30/30 [00:00<00:00, 4456.97it/s]\u001b[A\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 30/30 [00:00<00:00, 5193.76it/s]\u001b[A\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 30/30 [00:00<00:00, 5190.33it/s]\u001b[A\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 30/30 [00:00<00:00, 4505.32it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cascades: \n",
      "\n",
      " Simulation stopped at timestep  4 \n",
      " Diffusion has been completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "path = pathlib.Path(\"../src\")\n",
    "sys.path.insert(0, str(path))\n",
    "from womg.__main__ import womg_main\n",
    "\n",
    "womg_main(virality=2, gn_strength=0, numb_docs=30, int_mode='nmf', homophily=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd Output ; ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!cd ../Output/ ; ls ; pwd #cat Propagations0.txt cwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the parameters by the help page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(womg_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will produce a synthetic propagation dataset on the [Digg network dataset](https://www.isi.edu/~lerman/downloads/digg2009.html). This dataset consists in: graph dataset and diffusion dataset. We used the first as input of WoMG for generating diffusions and analyse results. \n",
    "\n",
    "We set:\n",
    "\n",
    "1. the number of steps equal to 100\n",
    "2. number of generated docs equal to 3553\n",
    "3. virality exponent of the docs distribution equal to 0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!python3 ../src/womg/__main__.py --graph ../data/graph/lesmiserables/lesmiserables_edgelist.txt --topics 2 --homophily 0 --int_mode n2i --steps 100 --docs 3553  --virality 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the actions using digg network as input can be done using simulation_index=_tutorial.\n",
    "\n",
    "The real dataset analysis provides the following results:\n",
    "\n",
    "    items actions [max, min, avg]:   6265 105 505\n",
    "\n",
    "    users actions [max, min, avg]:   3415 20 115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the synthetic dataset results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "womg_main(numb_docs=20, virality=0.01, gn_strength=0, numb_topics=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simulation_index = \"2\"\n",
    "#output_path = pathlib.Path.cwd().parent / \"Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_prop = output_path / str(\"Propagations\"+str(simulation_index)+\".txt\")\n",
    "#file_topic = output_path / str(\"Topics_descript\"+str(simulation_index)+\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(file_prop, sep=' ', names=['time', 'item', 'node'])\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#items_act = df.groupby('item').node.nunique()\n",
    "#print(items_act.max(), round(items_act.mean(), 2), items_act.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#users_act = df.groupby('node').item.nunique()\n",
    "#print(users_act.max(), round(users_act.mean(), 2), users_act.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPERIMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "path = pathlib.Path(\"../src\")\n",
    "sys.path.insert(0, str(path))\n",
    "from __main__ import womg_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [10]\n",
    "docs = [10]\n",
    "steps = [100] \n",
    "beta = [0.1]\n",
    "homophily = [-1, -0.5, 0, 0.5, 1]\n",
    "virality = [0.01, 0.05]\n",
    "god_node_strength = [0] \n",
    "influence_strength = [0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args_list = []\n",
    "\n",
    "nr_experiments = 10 \n",
    "\n",
    "for t in topics:\n",
    "    for d in docs:\n",
    "        for s in steps:\n",
    "            for b in beta:\n",
    "                for h in homophily:\n",
    "                    for v in virality:\n",
    "                        for g in god_node_strength:\n",
    "                            for f in influence_strength:\n",
    "                                for seed in range(nr_experiments):\n",
    "                                    args = [t, d, s, b, h, v, g, f, seed]\n",
    "                                    args_list.append(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_out =  pathlib.Path.cwd().parent / \"Simulation\"\n",
    "#graph_path = pathlib.Path.cwd().parent / str(\"data/graph/digg/digg_edgelist.txt\")\n",
    "graph_path = pathlib.Path.cwd().parent / str(\"data/graph/lesmiserables/lesmiserables_edgelist.txt\")\n",
    "#graph_path = pathlib.Path.cwd().parent / str(\"data/graph/wiki_vote/wiki_vote_edgelist.txt\")\n",
    "directed = False\n",
    "int_mode = 'n2i'\n",
    "norm_prior = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_analysis(graph_path):\n",
    "    G = nx.read_edgelist(graph_path)\n",
    "    print('avg clustering coeff ', nx.average_clustering(G))\n",
    "    print('numb of connected components: ', (nx.number_connected_components(G)))\n",
    "    print('numb of triangles: ', float(sum(nx.triangles(G).values()))/3)\n",
    "    print('Assortativity: ', nx.degree_assortativity_coefficient(G))\n",
    "\n",
    "    degree = np.array(list(dict(G.degree).values()))\n",
    "\n",
    "    plt.figure(figsize=(9,7))\n",
    "    plt.hist(degree, bins=100, normed=True)\n",
    "\n",
    "    plt.xticks(fontsize=17)\n",
    "    plt.yticks(fontsize=17)\n",
    "    plt.xlabel('Degree', fontsize=17)\n",
    "    plt.ylabel('$P(k)$', fontsize=17)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_analysis(graph_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "def experiment(args_list):\n",
    "    for args in tqdm_notebook(args_list):\n",
    "        t, d, s, b, h, v, g, f, seed = args\n",
    "        womg_main(path_out=path_out, graph_path=graph_path,\n",
    "                  directed=directed, int_mode=int_mode,\n",
    "                  numb_topics=t, numb_docs=d, numb_steps=s, beta=b, \n",
    "                  homophily=h, virality=v, gn_strength=g, infl_strength=f,\n",
    "                  seed=42*seed+(d+t)*8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experiment(args_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "def statistics(path):\n",
    "    result = []\n",
    "    for _ in range(len(args_list)):\n",
    "        file_prop = path / str(\"Propagations\"+str(_)+\".txt\")\n",
    "        file_topic = path / str(\"Topics_descript\"+str(_)+\".txt\")\n",
    "        df = pd.read_csv(file_prop, sep=' ', names=['time', 'item', 'node'])\n",
    "        mean_items_act = round(df.groupby('item').node.nunique().mean(), 2)\n",
    "        mean_users_act = round(df.groupby('node').item.nunique().mean(), 2)\n",
    "        #print(mean_items_act)\n",
    "        result.append(args_list[_]+[mean_items_act, mean_users_act,])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = statistics(path_out)\n",
    "df = pd.DataFrame(stat, columns=['t', 'd', 's', 'b', 'h', 'v', 'g', 'f', 'seed', 'mean_it_act', 'mean_us_act'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NaN values correspond to low virality 0.1\n",
    "df[df.isnull().any(axis=1)].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average items activations\n",
    "df_i = df.groupby(['h', 'v'])['mean_it_act'].mean().unstack()\n",
    "df_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax1.scatter(x=df_i.iloc[0].index, y=df_i.iloc[0], c='b', marker=\"o\", label='h=-1')\n",
    "ax1.scatter(x=df_i.iloc[0].index, y=df_i.iloc[2],  c='r', marker=\"o\", label='h=0')\n",
    "ax1.scatter(x=df_i.iloc[0].index, y=df_i.iloc[4],  c='g', marker=\"o\", label='h=1')\n",
    "ax1.legend(fontsize=25)\n",
    "plt.xlabel('virality', fontsize=25)\n",
    "plt.ylabel('items act', fontsize=25)\n",
    "plt.tick_params(labelsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax1.scatter(x=df_i.iloc[0].index, y=df_i.iloc[0], c='b', marker=\"o\", label='h=-1')\n",
    "ax1.scatter(x=df_i.iloc[0].index, y=df_i.iloc[2],  c='r', marker=\"o\", label='h=0')\n",
    "ax1.scatter(x=df_i.iloc[0].index, y=df_i.iloc[4],  c='g', marker=\"o\", label='h=1')\n",
    "ax1.legend(fontsize=25)\n",
    "plt.xlabel('virality', fontsize=25)\n",
    "plt.ylabel('items act', fontsize=25)\n",
    "plt.tick_params(labelsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "fig = plt.figure(figsize=(12,9))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "\n",
    "ax1.scatter(x=df_i.index, y=df_i.iloc[0], c='b', marker=\"o\", label='v=0.1')\n",
    "ax1.scatter(x=df_i.index, y=df_i.iloc[1],  c='r', marker=\"o\", label='v=1')\n",
    "ax1.scatter(x=df_i.index, y=df_i.iloc[2],  c='g', marker=\"o\", label='v=10')\n",
    "ax1.legend(fontsize=25)\n",
    "plt.xlabel('homophily', fontsize=25)\n",
    "plt.ylabel('items act', fontsize=25)\n",
    "plt.tick_params(labelsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i.iloc[0].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average users activations\n",
    "df_u = df.groupby(['h', 'v'])['mean_us_act'].mean().unstack()\n",
    "df_u.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cdf of simulation 0 - items activation\n",
    "\n",
    "file_prop = path_out / str(\"Propagations\"+str(0)+\".txt\")\n",
    "file_topic = path_out / str(\"Topics_descript\"+str(0)+\".txt\")\n",
    "df = pd.read_csv(file_prop, sep=' ', names=['time', 'item', 'node'])\n",
    "mean_items_act = round(df.groupby('item').node.nunique().mean(), 2)\n",
    "\n",
    "#sns.distplot(df.groupby('item'), hist_kws={'cumulative' : True})\n",
    "#plt.show()\n",
    "miss = pd.Series([0 for _ in ['1','2','3','4','5','6','7','9']], index =['1','2','3','4','5','6','7','9'])\n",
    "complete = df.groupby('item').node.nunique().append(miss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "plt.hist(complete, cumulative=True, normed=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### virality plot\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "path = pathlib.Path('../Output/')\n",
    "\n",
    "file_idx = [i for i in range(len(viralities))]\n",
    "#file_idx = [0, 1]\n",
    "\n",
    "y_item = []\n",
    "x_item = []\n",
    "y_user = []\n",
    "x_user = []\n",
    "cdf_data = {}\n",
    "cdf_data['item'] = {}\n",
    "cdf_data['user'] = {}\n",
    "for i in tqdm(file_idx):\n",
    "    file_info = path / str(\"Network_info_sim\"+str(i)+\".txt\")\n",
    "    file_prop = path / str(\"Diffusion_formatted_output_sim\"+str(i)+\".txt\")\n",
    "    # data for cdf plot\n",
    "    cdf_data['item'][i] = []\n",
    "    cdf_data['user'][i] = []\n",
    "    ########################\n",
    "    info_str = extract(file_info)\n",
    "    info = to_dict(info_str, typ=True)\n",
    "    prop = extract(file_prop)\n",
    "    cascades = to_dict(prop, typ=False)\n",
    "    items_data = items_actions(cascades, plot=False)\n",
    "    users_data = users_actions(cascades, info=info)\n",
    "    for n in range(len(items_data)):\n",
    "        cdf_data['item'][i].append(items_data[n])\n",
    "        y_item.append(items_data[n])\n",
    "        x_item.append(viralities[i])\n",
    "    for n in range(len(users_data)):\n",
    "        cdf_data['user'][i].append(users_data[n])\n",
    "        y_user.append(users_data[n])\n",
    "        x_user.append(viralities[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,11))\n",
    "\n",
    "plt.xlabel('virality', fontsize=22)\n",
    "plt.ylabel('items actions', fontsize=22)\n",
    "\n",
    "ax = sns.violinplot(x=x_item, y=y_item)\n",
    "sns.set()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#fig.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cdf plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,11))\n",
    "\n",
    "\n",
    "file_idx = [i for i in range(len(viralities))]\n",
    "\n",
    "\n",
    "cdf_hist = {}\n",
    "cdf_hist['user'] = {}\n",
    "cdf_hist['item'] = {}\n",
    "for i in [0, 1]:\n",
    "    # evaluate the histogram\n",
    "    cumulative = []\n",
    "    values, base = np.histogram(cdf_data['item'][i], bins=50)\n",
    "    cdf_hist['item'][i] = (values, base)\n",
    "    \n",
    "for i in [0, 1]:\n",
    "    #evaluate the cumulative\n",
    "    cumulative = np.cumsum(cdf_hist['item'][i][0])/3553\n",
    "    # plot the cumulative function\n",
    "    plt.plot(base[:-1], cumulative, linewidth=5)\n",
    "    #print(cumulative)\n",
    "    plt.xlabel('actions', fontsize=33)\n",
    "    plt.ylabel('CDF', fontsize=33)\n",
    "    plt.tick_params(labelsize=17)\n",
    "    #plt.yscale('log')\n",
    "    #plt.xscale('log')\n",
    "    plt.locator_params(axis='y', nbins=20)\n",
    "    plt.locator_params(axis='x', nbins=20)\n",
    "    plt.title('items CDF', fontsize=33)\n",
    "    plt.legend(['virality-exp=2', 'virality-exp=0.1', 'virality-exp=0.11', 'virality-exp=0.45', 'virality-exp=0.45'], \n",
    "               fontsize=33)\n",
    "plt.show()\n",
    "#fig.savefig()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
