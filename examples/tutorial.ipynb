{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *WoMG*: tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial for *WoMG*. The WoMG software generates synthetic datasets of documents cascades on network. It starts with any (un)directed, (un)weighted graph and a collection of documents and it outputs the propagation DAGs of the docs through the network. Diffusion process is guided by the nodes underlying preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOC:\n",
    "* [Demo](#Demo)\n",
    "* [Help](#Help)\n",
    "* [Usage](#Usage)\n",
    "* [Analysis](#Analysis)\n",
    "* [Statistics](#Statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will run WoMG with the default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../src/womg_main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Output/ ; ls ; #cat Diffusion_formatted_output_sim0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the parameters by the help page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../src/womg_main.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set of quantitative parameters are:\n",
    "\n",
    "1. number of topics to be considered in the topic distributions of documents and nodes interests; it has to be less than number of dimensions of the nodes' space provided by node2vec\n",
    "2. number of documents TO BE GENERATED by lda, giving this parameter lda will be directly set to generative mode\n",
    "3. steps of the diffusion simulation\n",
    "4. H degree of homophily. Node2vec is used as baseline for generating interests vectors of the nodes starting from the given graph. Parameters *p* and *q* can achieve different decoded degree of homophily and structural equivalence (see paper). The best mix of them can be achieved only by a deep analysis of the network and a grid searh on the parameters. In order to pursuit generality in the input graph we use three degree of mixing: structural equivalence predominant, deepWalk (p=1, q=1), homophily predominant (which are not the best for representing the graph!).  1-H is the degree of social influence between nodes; which is the percentage of the avg interests vecs norms to be assigned to the influence vectors.\n",
    "5. percentage of active nodes with respect to the total number of nodes in the intial configuration (before diffusion) for each doc.\n",
    "6. virality of the doc; if virality is high, exponent of the power law is high and threshold for activation is low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next parameters concern input graph, input documents and the node2vec original parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will produce a synthetic propagation dataset on the [Digg network dataset](https://www.isi.edu/~lerman/downloads/digg2009.html). This dataset consists in: graph dataset and diffusion dataset. We used the first as input of WoMG for generating diffusions and analyse results. \n",
    "\n",
    "We set:\n",
    "\n",
    "1. the number of steps equal to 100\n",
    "2. the maximum percentage of active nodes per doc equal to 0.065\n",
    "3. number of generated docs equal to 3553\n",
    "4. virality exponent of the docs distribution equal to 0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 ../src/main.py --graph ../data/graph/digg/digg_edgelist.txt --directed --steps 100 --actives 0.065 --docs 3553  --virality 0.009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the actions using digg network as input can be done using simulation_index=_tutorial.\n",
    "\n",
    "The real dataset analysis provides the following results:\n",
    "\n",
    "    items actions [max, min, avg]:   6265 105 505\n",
    "\n",
    "    users actions [max, min, avg]:   3415 20 115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_index = \"_tutorial\"\n",
    "output_path = pathlib.Path.cwd() / \"Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = output_path / str(\"Network_info_sim\"+str(simulation_index)+\".txt\")\n",
    "file_prop = output_path / str(\"Diffusion_formatted_output_sim\"+str(simulation_index)+\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_in):\n",
    "    '''\n",
    "    Returns file from the given input path\n",
    "    '''\n",
    "    if str(pathlib.Path(file_in).suffix) == '.txt':\n",
    "        with open(file_in, 'r') as f:\n",
    "            s = f.readlines()\n",
    "    if str(pathlib.Path(file_in).suffix) == '.pickle':\n",
    "        with open(file_in, 'rb') as f:\n",
    "            s = pickle.load(f)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(inp, typ=False):\n",
    "    '''\n",
    "    if typ:\n",
    "        Returns info input (inp) in dict format\n",
    "    if not typ:\n",
    "        Returns cascades in a dict format:\n",
    "        (outer)first key: time, (inner)second key: item, \n",
    "        value: new active nodes\n",
    "    '''\n",
    "    \n",
    "    if typ:\n",
    "        info_dict = ast.literal_eval(str(inp).replace('[','').replace(']','').replace('\"',''))\n",
    "        out_dict = info_dict\n",
    "        \n",
    "    else:   \n",
    "        prop_dict = {}\n",
    "        index = 0\n",
    "        for i in range(2, len(prop), 2):\n",
    "            inp[i] = inp[i].replace('\\n', '')\n",
    "            inp[i] = inp[i].replace('set()','None')\n",
    "            prop_dict[index] = ast.literal_eval(prop[i])\n",
    "            index += 1\n",
    "\n",
    "        out_dict = prop_dict\n",
    "           \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_str = extract(file_info)\n",
    "info = to_dict(info_str, typ=True)\n",
    "prop = extract(file_prop)\n",
    "cascades = to_dict(prop, typ=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items actions\n",
    "def items_actions(cascades, plot=False):\n",
    "    '''\n",
    "    Returns the vector of all items' actions\n",
    "    each entry is the the number of activations(actions)\n",
    "    for the item identified by entry-index\n",
    "    '''\n",
    "    numb_docs = max(cascades[0].keys())\n",
    "    items_action_vec = [0 for i in range(numb_docs+1)]\n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                items_action_vec[item] += len(cascades[step][item])\n",
    "            #if cascades[step][item] == None:\n",
    "                #print(item)\n",
    "    #print(items_action_vec)\n",
    "    if plot:\n",
    "        plt.hist(items_action_vec)\n",
    "        plt.show()\n",
    "    \n",
    "    print('items actions [max, min, avg]: ', int(max(items_action_vec)), int(min(items_action_vec)), int(np.mean(items_action_vec)))\n",
    "    return items_action_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_data = items_actions(cascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users actions\n",
    "def users_actions(cascades):\n",
    "    '''\n",
    "    Returns the vector of all users' actions\n",
    "    each entry is the the number of activations(actions)\n",
    "    for the user identified by entry-index\n",
    "    '''\n",
    "    numb_nodes = int(info['numb_nodes'])\n",
    " \n",
    "        \n",
    "    # defining dict\n",
    "    users_actions_dict = {}\n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                for node in cascades[step][item]:\n",
    "                    users_actions_dict[node] = 0\n",
    "                    \n",
    "    # counting            \n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                for node in cascades[step][item]:\n",
    "                    users_actions_dict[node] += 1\n",
    "                    \n",
    "    users_actions_vec = [0 for i in range(numb_nodes)]\n",
    "    for key, index in zip(sorted(users_actions_dict.keys()), range(numb_nodes)):\n",
    "        users_actions_vec[index] = users_actions_dict[key]\n",
    "    \n",
    "    print('users actions [max, min, avg]: ',int(max(users_actions_vec)),\n",
    "          int(min(users_actions_vec)), int(np.mean(users_actions_vec)))\n",
    "    return users_actions_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_data = users_actions(cascades)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "path = pathlib.Path(\"../src\")\n",
    "sys.path.insert(0, str(path))\n",
    "from womg_main import womg_main\n",
    "\n",
    "help(womg_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(numb_docs=None, viralities, actives, topics):\n",
    "    '''\n",
    "    Run womg with different sets of parameters\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        numb_docs : int\n",
    "            number of documents to be generated\n",
    "            (Default None: you need to pass a docs folder path)\n",
    "\n",
    "        viralities : iterable/float\n",
    "            array containing viralitiy params\n",
    "\n",
    "        actives : iterable/float\n",
    "            array containing actives_perc params\n",
    "            (percentage of actives nodes for an items in the initial step)\n",
    "\n",
    "        topics : iterable/int\n",
    "            array containing numb_topics params\n",
    "            \n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        See womg reference for more details: help(womg_main)\n",
    "        \n",
    "    '''\n",
    "    for v in viralities:\n",
    "        for a in actives:\n",
    "            for t in topics:      \n",
    "                womg_main(numb_topics=t, actives_perc=a, virality=v, numb_docs=numb_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "viralities = [2, 1, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05]\n",
    "actives = [0.065]\n",
    "topics = [15]\n",
    "\n",
    "simulate(numb_docs=3553, \n",
    "         viralities=viralities, \n",
    "         actives=actives, \n",
    "         topics=topics\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### virality plot\n",
    "\n",
    "'''\n",
    "file_idx = [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
    "viralities = [2, 1, 0.5, 0.3, 0.5, 0.35, 0.25, 0.2, 0.1]\n",
    "'''\n",
    "'''\n",
    "\n",
    "file_idx = [0, 2, 6,  16]\n",
    "viralities = [2, 0.5, 0.35,  0.11]\n",
    "'''\n",
    "path = '/Users/Cinus/University/Tesi/womg_git/Code/Library2.0/Output/Diffusion_formatted_output_sim'\n",
    "\n",
    "\n",
    "file_idx = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "viralities = [0.5, 0.45, 0.4, 0.38, 0.35, 0.32, 0.3, 0.28, 0.25, 0.22, 0.2, 0.18, 0.15, 0.12]\n",
    "\n",
    "y_item = []\n",
    "x_item = []\n",
    "y_user = []\n",
    "x_user = []\n",
    "cdf_data = {}\n",
    "cdf_data['item'] = {}\n",
    "cdf_data['user'] = {}\n",
    "for i in tqdm(range(len(file_idx))):\n",
    "    # data for cdf plot\n",
    "    cdf_data['item'][i] = []\n",
    "    cdf_data['user'][i] = []\n",
    "    ########################\n",
    "    file = path + str(file_idx[i]) + '.txt'\n",
    "    prop = extract(file)\n",
    "    cascades = to_dict(prop)\n",
    "    items_data = items_actions(cascades, plot=False)\n",
    "    users_data = users_actions(cascades)\n",
    "    for n in range(len(items_data)):\n",
    "        cdf_data['item'][i].append(items_data[n])\n",
    "        y_item.append(items_data[n])\n",
    "        x_item.append(viralities[i])\n",
    "    for n in range(len(users_data)):\n",
    "        cdf_data['user'][i].append(users_data[n])\n",
    "        y_user.append(users_data[n])\n",
    "        x_user.append(viralities[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,11))\n",
    "\n",
    "plt.xlabel('virality', fontsize=22)\n",
    "plt.ylabel('items actions', fontsize=22)\n",
    "\n",
    "ax = sns.violinplot(x=x_item, y=y_item)\n",
    "sns.set()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig.savefig('/Users/Cinus/University/Tesi/Tesi/Images/violin_pres.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cdf plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,11))\n",
    "\n",
    "\n",
    "file_idx = [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n",
    "viralities = [0.5, 0.45, 0.4, 0.38, 0.35, 0.32, 0.3, 0.28, 0.25, 0.22, 0.2, 0.18, 0.15, 0.12]\n",
    "\n",
    "\n",
    "cdf_hist = {}\n",
    "cdf_hist['user'] = {}\n",
    "cdf_hist['item'] = {}\n",
    "for i in [2, 9, 13]:\n",
    "    # evaluate the histogram\n",
    "    cumulative = []\n",
    "    values, base = np.histogram(cdf_data['item'][i], bins=50)\n",
    "    cdf_hist['item'][i] = (values, base)\n",
    "    \n",
    "for i in [2, 9, 13]:\n",
    "    #evaluate the cumulative\n",
    "    cumulative = np.cumsum(cdf_hist['item'][i][0])/3553\n",
    "    # plot the cumulative function\n",
    "    plt.plot(base[:-1], cumulative, linewidth=5)\n",
    "    #print(cumulative)\n",
    "    plt.xlabel('actions', fontsize=33)\n",
    "    plt.ylabel('CDF', fontsize=33)\n",
    "    plt.tick_params(labelsize=17)\n",
    "    #plt.yscale('log')\n",
    "    #plt.xscale('log')\n",
    "    plt.locator_params(axis='y', nbins=20)\n",
    "    plt.locator_params(axis='x', nbins=20)\n",
    "    plt.title('items CDF', fontsize=33)\n",
    "    plt.legend(['virality-exp=0.5', 'virality-exp=0.3', 'virality-exp=0.11', 'virality-exp=0.45', 'virality-exp=0.45'], \n",
    "               fontsize=33)\n",
    "plt.show()\n",
    "#fig.savefig('/Users/Cinus/University/Tesi/Tesi/Images/cdf_items.pdf')\n",
    "fig.savefig('/Users/Cinus/University/Tesi/Presentazioni/Tesi_Template/Downloads/cdf_items.pdf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
