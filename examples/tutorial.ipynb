{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *WoMG*: tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial for *WoMG*. The WoMG software generates synthetic datasets of documents cascades on network. It starts with any (un)directed, (un)weighted graph and a collection of documents and it outputs the propagation DAGs of the docs through the network. Diffusion process is guided by the nodes underlying preferences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOC:\n",
    "* [Demo](#Demo)\n",
    "* [Help](#Help)\n",
    "* [Usage](#Usage)\n",
    "* [Analysis](#Analysis)\n",
    "* [Statistics](#Statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will run WoMG with the default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 ../src/main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd ../Output/ ; ls ; #cat Diffusion_formatted_output_sim0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the parameters by the help page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [-v] [--topics [K]] [--docs [D]] [--steps [T]]\r\n",
      "               [--homophily [H]] [--actives [A]] [--virality [V]]\r\n",
      "               [--graph [GRAPH]] [--weighted] [--unweighted] [--directed]\r\n",
      "               [--undirected] [--docs-folder [DOCS]] [--output OUTPUT]\r\n",
      "               [--format FORMAT] [--seed [SEED]] [--dimensions d]\r\n",
      "               [--walk-length w] [--num-walks nw] [--window-size ws]\r\n",
      "               [--iter ITER] [--workers WORKERS] [--p P] [--q Q]\r\n",
      "\r\n",
      "optional arguments:\r\n",
      "  -h, --help            show this help message and exit\r\n",
      "  -v, --version         show program's version number and exit\r\n",
      "  --topics [K]          Number of topics in the topic model. Default 15. K<d\r\n",
      "  --docs [D]            Number of docs to be generated. Default 100\r\n",
      "  --steps [T]           Number of time steps for diffusion\r\n",
      "  --homophily [H]       0<=H<=1 :degree of homophily decoded from the given\r\n",
      "                        network. 1-H is degree of influence between nodes;\r\n",
      "                        reccommended values are: 0, 0.5, 1. Default 0.5\r\n",
      "  --actives [A]         Maximum percentage of active nodes in first step of\r\n",
      "                        simulation on an item with respect to the number of\r\n",
      "                        nodes. Default 0.5\r\n",
      "  --virality [V]        Exponent of the powerlaw distribution for documents\r\n",
      "                        viralities. P(x; a) = x^{-a}, 0 <= x <=1. Deafault a=1\r\n",
      "  --graph [GRAPH]       Input path of the graph edgelist\r\n",
      "  --weighted            boolean specifying (un)weighted. Default unweighted\r\n",
      "  --unweighted\r\n",
      "  --directed            graph is (un)directed. Default undirected\r\n",
      "  --undirected\r\n",
      "  --docs-folder [DOCS]  Input path of the documents folder\r\n",
      "  --output OUTPUT       Outputs path\r\n",
      "  --format FORMAT       Outputs format\r\n",
      "  --seed [SEED]         Seed (int) for random distribution extractions\r\n",
      "  --dimensions d        Number of dimensions for node2vec. Default 128\r\n",
      "  --walk-length w       length of walk per source. Default 80\r\n",
      "  --num-walks nw        number of walks per source. Default 10\r\n",
      "  --window-size ws      context size for optimization. Default 10\r\n",
      "  --iter ITER           number of epochs in SGD\r\n",
      "  --workers WORKERS     number of parallel workers. Default 8\r\n",
      "  --p P                 manually set BFS parameter; else: it is set by H\r\n",
      "  --q Q                 manually set DFS parameter; else: it is set by H\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ../src/main.py --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set of quantitative parameters are:\n",
    "\n",
    "1. number of topics to be considered in the topic distributions of documents and nodes interests; it has to be less than number of dimensions of the nodes' space provided by node2vec\n",
    "2. number of documents TO BE GENERATED by lda, giving this parameter lda will be directly set to generative mode\n",
    "3. steps of the diffusion simulation\n",
    "4. H degree of homophily. Node2vec is used as baseline for generating interests vectors of the nodes starting from the given graph. Parameters *p* and *q* can achieve different decoded degree of homophily and structural equivalence (see paper). The best mix of them can be achieved only by a deep analysis of the network and a grid searh on the parameters. In order to pursuit generality in the input graph we use three degree of mixing: structural equivalence predominant, deepWalk (p=1, q=1), homophily predominant (which are not the best for representing the graph!).  1-H is the degree of social influence between nodes; which is the percentage of the avg interests vecs norms to be assigned to the influence vectors.\n",
    "5. percentage of active nodes with respect to the total number of nodes in the intial configuration (before diffusion) for each doc.\n",
    "6. virality of the doc; if virality is high, exponent of the power law is high and threshold for activation is low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next parameters concern input graph, input documents and the node2vec original parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will produce a synthetic propagation dataset on the [Digg network dataset](https://www.isi.edu/~lerman/downloads/digg2009.html). This dataset consists in: graph dataset and diffusion dataset. We used the first as input of WoMG for generating diffusions and analyse results. \n",
    "\n",
    "We set:\n",
    "\n",
    "1. the number of steps equal to 100\n",
    "2. the maximum percentage of active nodes per doc equal to 0.065\n",
    "3. number of generated docs equal to 3553\n",
    "4. virality exponent of the docs distribution equal to 0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 ../src/main.py --graph ../data/graph/digg/digg_edgelist.txt --directed --steps 100 --actives 0.065 --docs 3553  --virality 0.009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the actions using digg network as input can be done using simulation_index=_tutorial.\n",
    "\n",
    "The real dataset analysis provides the following results:\n",
    "\n",
    "    items actions [max, min, avg]:   6265 105 505\n",
    "\n",
    "    users actions [max, min, avg]:   3415 20 115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_index = \"_tutorial\"\n",
    "output_path = pathlib.Path.cwd() / \"Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = output_path / str(\"Network_info_sim\"+str(simulation_index)+\".txt\")\n",
    "file_prop = output_path / str(\"Diffusion_formatted_output_sim\"+str(simulation_index)+\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_in):\n",
    "    '''\n",
    "    Returns file from the given input path\n",
    "    '''\n",
    "    if str(pathlib.Path(file_in).suffix) == '.txt':\n",
    "        with open(file_in, 'r') as f:\n",
    "            s = f.readlines()\n",
    "    if str(pathlib.Path(file_in).suffix) == '.pickle':\n",
    "        with open(file_in, 'rb') as f:\n",
    "            s = pickle.load(f)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(inp, typ=False):\n",
    "    '''\n",
    "    if typ:\n",
    "        Returns info input (inp) in dict format\n",
    "    if not typ:\n",
    "        Returns cascades in a dict format:\n",
    "        (outer)first key: time, (inner)second key: item, \n",
    "        value: new active nodes\n",
    "    '''\n",
    "    \n",
    "    if typ:\n",
    "        info_dict = ast.literal_eval(str(inp).replace('[','').replace(']','').replace('\"',''))\n",
    "        out_dict = info_dict\n",
    "        \n",
    "    else:   \n",
    "        prop_dict = {}\n",
    "        index = 0\n",
    "        for i in range(2, len(prop), 2):\n",
    "            inp[i] = inp[i].replace('\\n', '')\n",
    "            inp[i] = inp[i].replace('set()','None')\n",
    "            prop_dict[index] = ast.literal_eval(prop[i])\n",
    "            index += 1\n",
    "\n",
    "        out_dict = prop_dict\n",
    "           \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_str = extract(file_info)\n",
    "info = to_dict(info_str, typ=True)\n",
    "prop = extract(file_prop)\n",
    "cascades = to_dict(prop, typ=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items actions\n",
    "def items_actions(cascades, plot=False):\n",
    "    '''\n",
    "    Returns the vector of all items' actions\n",
    "    each entry is the the number of activations(actions)\n",
    "    for the item identified by entry-index\n",
    "    '''\n",
    "    numb_docs = max(cascades[0].keys())\n",
    "    items_action_vec = [0 for i in range(numb_docs+1)]\n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                items_action_vec[item] += len(cascades[step][item])\n",
    "            #if cascades[step][item] == None:\n",
    "                #print(item)\n",
    "    #print(items_action_vec)\n",
    "    if plot:\n",
    "        plt.hist(items_action_vec)\n",
    "        plt.show()\n",
    "    \n",
    "    print('items actions [max, min, avg]: ', int(max(items_action_vec)), int(min(items_action_vec)), int(np.mean(items_action_vec)))\n",
    "    return items_action_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "items actions [max, min, avg]:  7559 0 505\n"
     ]
    }
   ],
   "source": [
    "items_data = items_actions(cascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users actions\n",
    "def users_actions(cascades):\n",
    "    '''\n",
    "    Returns the vector of all users' actions\n",
    "    each entry is the the number of activations(actions)\n",
    "    for the user identified by entry-index\n",
    "    '''\n",
    "    numb_nodes = int(info['numb_nodes'])\n",
    " \n",
    "        \n",
    "    # defining dict\n",
    "    users_actions_dict = {}\n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                for node in cascades[step][item]:\n",
    "                    users_actions_dict[node] = 0\n",
    "                    \n",
    "    # counting            \n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                for node in cascades[step][item]:\n",
    "                    users_actions_dict[node] += 1\n",
    "                    \n",
    "    users_actions_vec = [0 for i in range(numb_nodes)]\n",
    "    for key, index in zip(sorted(users_actions_dict.keys()), range(numb_nodes)):\n",
    "        users_actions_vec[index] = users_actions_dict[key]\n",
    "    \n",
    "    print('users actions [max, min, avg]: ',int(max(users_actions_vec)),\n",
    "          int(min(users_actions_vec)), int(np.mean(users_actions_vec)))\n",
    "    return users_actions_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users actions [max, min, avg]:  157 73 113\n"
     ]
    }
   ],
   "source": [
    "users_data = users_actions(cascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
