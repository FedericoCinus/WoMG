{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *WoMG*: tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a tutorial for *WoMG*. The WoMG software generates synthetic datasets of documents cascades on network. It starts with any (un)directed, (un)weighted graph and a collection of documents and it outputs the propagation DAGs of the docs through the network. Diffusion process is guided by the nodes underlying preferences.\n",
    "\n",
    "\n",
    "First section will introduce a demo of the software.\n",
    "\n",
    "Second section will provide a basic usage with the [Digg](https://www.isi.edu/~lerman/downloads/digg2009.html) dataset used in the thesis. Digg dataset contains a network dataset and a propagation dataset.\n",
    "\n",
    "The Analysis section will analyse the synthetic dataset of propagations generated by WoMG using the Digg network as input graph; the real propagation values are reported at the end of the previous section. \n",
    "\n",
    "The statistics section is used for simulating different propagations with different parameters and plotting the results; this kind of statistics needs lot of computation by WoMG, so synthetic datasets are already produced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOC:\n",
    "* [Demo](#Demo)\n",
    "* [Help](#Help)\n",
    "* [Usage](#Usage)\n",
    "* [Analysis](#Analysis)\n",
    "* [Statistics](#Statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WoMG can be used both in command line and Jupyter notebook. The following codes will run WoMG with the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Cinus/Work/Progetti/WoMG/WoMG/examples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:00<00:00, 411015.90it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 39280.15it/s]\n",
      "100%|██████████| 254/254 [00:00<00:00, 10915.73it/s]\n",
      " 30%|███       | 3/10 [00:00<00:00, 27.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph\n",
      "No graph path provided \n",
      " DEMO Mode: generating cascades in les miserables network\n",
      "Formatting graph:\n",
      "Generating interests:\n",
      "../data/graph/lesmiserables/lesmiserables_edgelist.txt\n",
      "Walk iteration:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 26.47it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 3289.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing interest vectors: \n",
      "Reducing dimensions from  128  to  15\n",
      "Setting LDA in generative mode:  100  documents, with  15  topics.\n",
      "Training the LDA model ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 52%|█████▏    | 52/100 [00:00<00:00, 517.87it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:19,  5.05it/s]/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cascades: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 1272.78it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 3/100 [00:00<00:15,  6.42it/s]t/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 11591.60it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 99698.22it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulation stoped at timestep  4 \n",
      "No more nodes will activate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%run ../src/womg/__main__.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Jupyter notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:00<00:00, 494363.44it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 33537.01it/s]\n",
      "100%|██████████| 254/254 [00:00<00:00, 10679.38it/s]\n",
      " 30%|███       | 3/10 [00:00<00:00, 24.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Cinus/Work/Progetti/WoMG/WoMG/examples\n",
      "Loading graph\n",
      "No graph path provided \n",
      " DEMO Mode: generating cascades in les miserables network\n",
      "Formatting graph:\n",
      "Generating interests:\n",
      "../data/graph/lesmiserables/lesmiserables_edgelist.txt\n",
      "Walk iteration:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 24.92it/s]\n",
      "100%|██████████| 77/77 [00:00<00:00, 4046.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing interest vectors: \n",
      "Reducing dimensions from  128  to  15\n",
      "Setting LDA in generative mode:  100  documents, with  15  topics.\n",
      "Training the LDA model ..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      " 96%|█████████▌| 96/100 [00:00<00:00, 950.89it/s]\u001b[A\n",
      "  1%|          | 1/100 [00:00<00:11,  8.41it/s]/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 1594.22it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing cascades: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  3%|▎         | 3/100 [00:00<00:09,  9.86it/s]t/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 9672.10it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 22253.31it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 31775.03it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 42426.70it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 35335.33it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 47798.34it/s]\u001b[A\n",
      "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 100/100 [00:00<00:00, 59918.63it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Simulation stoped at timestep  9 \n",
      "No more nodes will activate\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "path = pathlib.Path(\"../src\")\n",
    "sys.path.insert(0, str(path))\n",
    "from womg.__main__ import womg_main\n",
    "\n",
    "womg_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!cd ../Output/ ; ls ; #cat Diffusion_formatted_output_sim0.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the parameters by the help page:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "help(womg_main)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set of quantitative parameters are:\n",
    "\n",
    "1. number of topics to be considered in the topic distributions of documents and nodes interests; it has to be less than number of dimensions of the nodes' space provided by node2vec\n",
    "2. number of documents TO BE GENERATED by lda, giving this parameter lda will be directly set to generative mode\n",
    "3. steps of the diffusion simulation\n",
    "4. H degree of homophily. Node2vec is used as baseline for generating interests vectors of the nodes starting from the given graph. Parameters *p* and *q* can achieve different decoded degree of homophily and structural equivalence (see paper). The best mix of them can be achieved only by a deep analysis of the network and a grid searh on the parameters. In order to pursuit generality in the input graph we use three degree of mixing: structural equivalence predominant, deepWalk (p=1, q=1), homophily predominant (which are not the best for representing the graph!).  1-H is the degree of social influence between nodes; which is the percentage of the avg interests vecs norms to be assigned to the influence vectors.\n",
    "5. percentage of active nodes with respect to the total number of nodes in the intial configuration (before diffusion) for each doc.\n",
    "6. virality of the doc; if virality is high, exponent of the power law is high and threshold for activation is low.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next parameters concern input graph, input documents and the node2vec original parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will produce a synthetic propagation dataset on the [Digg network dataset](https://www.isi.edu/~lerman/downloads/digg2009.html). This dataset consists in: graph dataset and diffusion dataset. We used the first as input of WoMG for generating diffusions and analyse results. \n",
    "\n",
    "We set:\n",
    "\n",
    "1. the number of steps equal to 100\n",
    "2. the maximum percentage of active nodes per doc equal to 0.065\n",
    "3. number of generated docs equal to 3553\n",
    "4. virality exponent of the docs distribution equal to 0.009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python3 ../src/womg/__main__.py --graph ../data/graph/digg/digg_edgelist.txt --directed --steps 100 --actives 0.065 --docs 3553  --virality 0.009"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of the actions using digg network as input can be done using simulation_index=_tutorial.\n",
    "\n",
    "The real dataset analysis provides the following results:\n",
    "\n",
    "    items actions [max, min, avg]:   6265 105 505\n",
    "\n",
    "    users actions [max, min, avg]:   3415 20 115"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the synthetic dataset results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pathlib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_index = \"_tutorial\"\n",
    "output_path = pathlib.Path.cwd() / \"Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info = output_path / str(\"Network_info_sim\"+str(simulation_index)+\".txt\")\n",
    "file_prop = output_path / str(\"Diffusion_formatted_output_sim\"+str(simulation_index)+\".txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### import functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(file_in):\n",
    "    '''\n",
    "    Returns file from the given input path\n",
    "    '''\n",
    "    if str(pathlib.Path(file_in).suffix) == '.txt':\n",
    "        with open(file_in, 'r') as f:\n",
    "            s = f.readlines()\n",
    "    if str(pathlib.Path(file_in).suffix) == '.pickle':\n",
    "        with open(file_in, 'rb') as f:\n",
    "            s = pickle.load(f)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dict(inp, typ=False):\n",
    "    '''\n",
    "    if typ:\n",
    "        Returns info input (inp) in dict format\n",
    "    if not typ:\n",
    "        Returns cascades in a dict format:\n",
    "        (outer)first key: time, (inner)second key: item, \n",
    "        value: new active nodes\n",
    "    '''\n",
    "    \n",
    "    if typ:\n",
    "        info_dict = ast.literal_eval(str(inp).replace('[','').replace(']','').replace('\"',''))\n",
    "        out_dict = info_dict\n",
    "        \n",
    "    else:   \n",
    "        prop_dict = {}\n",
    "        index = 0\n",
    "        for i in range(2, len(prop), 2):\n",
    "            inp[i] = inp[i].replace('\\n', '')\n",
    "            inp[i] = inp[i].replace('set()','None')\n",
    "            prop_dict[index] = ast.literal_eval(prop[i])\n",
    "            index += 1\n",
    "\n",
    "        out_dict = prop_dict\n",
    "           \n",
    "    return out_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_str = extract(file_info)\n",
    "info = to_dict(info_str, typ=True)\n",
    "prop = extract(file_prop)\n",
    "cascades = to_dict(prop, typ=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### analysis functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# items actions\n",
    "def items_actions(cascades, plot=False):\n",
    "    '''\n",
    "    Returns the vector of all items' actions\n",
    "    each entry is the the number of activations(actions)\n",
    "    for the item identified by entry-index\n",
    "    '''\n",
    "    numb_docs = max(cascades[0].keys())\n",
    "    items_action_vec = [0 for i in range(numb_docs+1)]\n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                items_action_vec[item] += len(cascades[step][item])\n",
    "            #if cascades[step][item] == None:\n",
    "                #print(item)\n",
    "    #print(items_action_vec)\n",
    "    if plot:\n",
    "        plt.hist(items_action_vec)\n",
    "        plt.show()\n",
    "    \n",
    "    print('items actions [max, min, avg]: ', int(max(items_action_vec)), int(min(items_action_vec)), int(np.mean(items_action_vec)))\n",
    "    return items_action_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items_data = items_actions(cascades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# users actions\n",
    "def users_actions(cascades, info):\n",
    "    '''\n",
    "    Returns the vector of all users' actions\n",
    "    each entry is the the number of activations(actions)\n",
    "    for the user identified by entry-index\n",
    "    '''\n",
    "    numb_nodes = int(info['numb_nodes'])\n",
    " \n",
    "        \n",
    "    # defining dict\n",
    "    users_actions_dict = {}\n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                for node in cascades[step][item]:\n",
    "                    users_actions_dict[node] = 0\n",
    "                    \n",
    "    # counting            \n",
    "    for step in cascades.keys():\n",
    "        for item in cascades[step].keys():\n",
    "            if cascades[step][item] != None:\n",
    "                for node in cascades[step][item]:\n",
    "                    users_actions_dict[node] += 1\n",
    "                    \n",
    "    users_actions_vec = [0 for i in range(numb_nodes)]\n",
    "    for key, index in zip(sorted(users_actions_dict.keys()), range(numb_nodes)):\n",
    "        users_actions_vec[index] = users_actions_dict[key]\n",
    "    \n",
    "    print('users actions [max, min, avg]: ',int(max(users_actions_vec)),\n",
    "          int(min(users_actions_vec)), int(np.mean(users_actions_vec)))\n",
    "    return users_actions_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_data = users_actions(cascades, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "path = pathlib.Path(\"../src\")\n",
    "sys.path.insert(0, str(path))\n",
    "from __main__ import womg_main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate(viralities, actives, topics, numb_docs=None, graph=None, directed=False):\n",
    "    '''\n",
    "    Run womg with different sets of parameters\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        numb_docs : int\n",
    "            number of documents to be generated\n",
    "            (Default None: you need to pass a docs folder path)\n",
    "\n",
    "        viralities : iterable/float\n",
    "            array containing viralitiy params\n",
    "\n",
    "        actives : iterable/float\n",
    "            array containing actives_perc params\n",
    "            (percentage of actives nodes for an items in the initial step)\n",
    "\n",
    "        topics : iterable/int\n",
    "            array containing numb_topics params\n",
    "            \n",
    "        \n",
    "        Notes\n",
    "        -----\n",
    "        See womg reference for more details: help(womg_main)\n",
    "        \n",
    "    '''\n",
    "    for t in topics:\n",
    "        for a in actives:\n",
    "            for v in viralities:      \n",
    "                womg_main(numb_topics=t, actives_perc=a, virality=v, numb_docs=numb_docs, \n",
    "                          path_in_graph=graph,\n",
    "                          directed=directed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#viralities = [2, 1, 0.5, 0.45, 0.4, 0.35, 0.3, 0.25, 0.2, 0.15, 0.1, 0.05, 0.01, 0.005]\n",
    "viralities = [2, 0.1]\n",
    "actives = [0.4]\n",
    "topics = [15]\n",
    "\n",
    "simulate(numb_docs=3553, \n",
    "         viralities=viralities, \n",
    "         actives=actives, \n",
    "         topics=topics,\n",
    "         graph='../data/graph/digg/digg_edgelist.txt',\n",
    "         directed=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### virality plot\n",
    "from tqdm import tqdm\n",
    "import pathlib\n",
    "path = pathlib.Path('../Output/')\n",
    "\n",
    "file_idx = [i for i in range(len(viralities))]\n",
    "#file_idx = [0, 1]\n",
    "\n",
    "y_item = []\n",
    "x_item = []\n",
    "y_user = []\n",
    "x_user = []\n",
    "cdf_data = {}\n",
    "cdf_data['item'] = {}\n",
    "cdf_data['user'] = {}\n",
    "for i in tqdm(file_idx):\n",
    "    file_info = path / str(\"Network_info_sim\"+str(i)+\".txt\")\n",
    "    file_prop = path / str(\"Diffusion_formatted_output_sim\"+str(i)+\".txt\")\n",
    "    # data for cdf plot\n",
    "    cdf_data['item'][i] = []\n",
    "    cdf_data['user'][i] = []\n",
    "    ########################\n",
    "    info_str = extract(file_info)\n",
    "    info = to_dict(info_str, typ=True)\n",
    "    prop = extract(file_prop)\n",
    "    cascades = to_dict(prop, typ=False)\n",
    "    items_data = items_actions(cascades, plot=False)\n",
    "    users_data = users_actions(cascades, info=info)\n",
    "    for n in range(len(items_data)):\n",
    "        cdf_data['item'][i].append(items_data[n])\n",
    "        y_item.append(items_data[n])\n",
    "        x_item.append(viralities[i])\n",
    "    for n in range(len(users_data)):\n",
    "        cdf_data['user'][i].append(users_data[n])\n",
    "        y_user.append(users_data[n])\n",
    "        x_user.append(viralities[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### violin plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,11))\n",
    "\n",
    "plt.xlabel('virality', fontsize=22)\n",
    "plt.ylabel('items actions', fontsize=22)\n",
    "\n",
    "ax = sns.violinplot(x=x_item, y=y_item)\n",
    "sns.set()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#fig.savefig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cdf plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,11))\n",
    "\n",
    "\n",
    "file_idx = [i for i in range(len(viralities))]\n",
    "\n",
    "\n",
    "cdf_hist = {}\n",
    "cdf_hist['user'] = {}\n",
    "cdf_hist['item'] = {}\n",
    "for i in [0, 1]:\n",
    "    # evaluate the histogram\n",
    "    cumulative = []\n",
    "    values, base = np.histogram(cdf_data['item'][i], bins=50)\n",
    "    cdf_hist['item'][i] = (values, base)\n",
    "    \n",
    "for i in [0, 1]:\n",
    "    #evaluate the cumulative\n",
    "    cumulative = np.cumsum(cdf_hist['item'][i][0])/3553\n",
    "    # plot the cumulative function\n",
    "    plt.plot(base[:-1], cumulative, linewidth=5)\n",
    "    #print(cumulative)\n",
    "    plt.xlabel('actions', fontsize=33)\n",
    "    plt.ylabel('CDF', fontsize=33)\n",
    "    plt.tick_params(labelsize=17)\n",
    "    #plt.yscale('log')\n",
    "    #plt.xscale('log')\n",
    "    plt.locator_params(axis='y', nbins=20)\n",
    "    plt.locator_params(axis='x', nbins=20)\n",
    "    plt.title('items CDF', fontsize=33)\n",
    "    plt.legend(['virality-exp=2', 'virality-exp=0.1', 'virality-exp=0.11', 'virality-exp=0.45', 'virality-exp=0.45'], \n",
    "               fontsize=33)\n",
    "plt.show()\n",
    "#fig.savefig()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
